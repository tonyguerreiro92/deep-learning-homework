{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Stock Predictor Using Fear and Greed Index\n",
    "\n",
    "In this notebook, you will build and train a custom LSTM RNN that uses a 10 day window of Bitcoin fear and greed index values to predict the 11th day closing price. \n",
    "\n",
    "You will need to:\n",
    "\n",
    "1. Prepare the data for training and testing\n",
    "2. Build and train a custom LSTM RNN\n",
    "3. Evaluate the performance of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "In this section, you will need to prepare the training and testing data for the model. The model will use a rolling 10 day window to predict the 11th day closing price.\n",
    "\n",
    "You will need to:\n",
    "1. Use the `window_data` function to generate the X and y values for the model.\n",
    "2. Split the data into 70% training and 30% testing\n",
    "3. Apply the MinMaxScaler to the X and y values\n",
    "4. Reshape the X_train and X_test data for the model. Note: The required input format for the LSTM is:\n",
    "\n",
    "```python\n",
    "reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hvplot.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "# Note: This is for the homework solution, but it is good practice to comment this out and run multiple experiments to evaluate your model\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import random\n",
    "random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fng_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-07-29</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-28</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-27</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-26</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-25</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fng_value\n",
       "date                  \n",
       "2019-07-29          19\n",
       "2019-07-28          16\n",
       "2019-07-27          47\n",
       "2019-07-26          24\n",
       "2019-07-25          42"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the fear and greed sentiment data for Bitcoin\n",
    "df = pd.read_csv('btc_sentiment.csv', index_col=\"date\", infer_datetime_format=True, parse_dates=True)\n",
    "df = df.drop(columns=\"fng_classification\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2019-07-25    9882.429688\n",
       "2019-07-26    9847.450195\n",
       "2019-07-27    9478.320313\n",
       "2019-07-28    9531.769531\n",
       "2019-07-29    9529.889648\n",
       "Name: Close, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the historical closing prices for Bitcoin\n",
    "df2 = pd.read_csv('btc_historic.csv', index_col=\"Date\", infer_datetime_format=True, parse_dates=True)['Close']\n",
    "df2 = df2.sort_index()\n",
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fng_value</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-07-25</th>\n",
       "      <td>42</td>\n",
       "      <td>9882.429688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-26</th>\n",
       "      <td>24</td>\n",
       "      <td>9847.450195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-27</th>\n",
       "      <td>47</td>\n",
       "      <td>9478.320313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-28</th>\n",
       "      <td>16</td>\n",
       "      <td>9531.769531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-29</th>\n",
       "      <td>19</td>\n",
       "      <td>9529.889648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fng_value        Close\n",
       "2019-07-25          42  9882.429688\n",
       "2019-07-26          24  9847.450195\n",
       "2019-07-27          47  9478.320313\n",
       "2019-07-28          16  9531.769531\n",
       "2019-07-29          19  9529.889648"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join the data into a single DataFrame\n",
    "df = df.join(df2, how=\"inner\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fng_value</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td>30</td>\n",
       "      <td>9114.719727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-02</th>\n",
       "      <td>15</td>\n",
       "      <td>8870.820313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-03</th>\n",
       "      <td>40</td>\n",
       "      <td>9251.269531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-04</th>\n",
       "      <td>24</td>\n",
       "      <td>8218.049805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-05</th>\n",
       "      <td>11</td>\n",
       "      <td>6937.080078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fng_value        Close\n",
       "2018-02-01          30  9114.719727\n",
       "2018-02-02          15  8870.820313\n",
       "2018-02-03          40  9251.269531\n",
       "2018-02-04          24  8218.049805\n",
       "2018-02-05          11  6937.080078"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function accepts the column number for the features (X) and the target (y)\n",
    "# It chunks the data up with a rolling window of Xt-n to predict Xt\n",
    "# It returns a numpy array of X any y\n",
    "def window_data(df, window, feature_col_number, target_col_number):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window - 1):\n",
    "        features = df.iloc[i:(i + window), feature_col_number]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Closing Prices using a 10 day window of previous fng values\n",
    "# Then, experiment with window sizes anywhere from 1 to 10 and see how the model performance changes\n",
    "window_size = 10\n",
    "\n",
    "# Column index 0 is the 'fng_value' column\n",
    "# Column index 1 is the `Close` column\n",
    "feature_column = 0\n",
    "target_column = 1\n",
    "X, y = window_data(df, window_size, feature_column, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 70% of the data for training and the remaineder for testing\n",
    "split = int(0.7 * len(X))\n",
    "X_train = X[: split - 1]\n",
    "X_test = X[split:]\n",
    "y_train = y[: split - 1]\n",
    "y_test = y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Use the MinMaxScaler to scale data between 0 and 1.\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(X)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "scaler.fit(y)\n",
    "y_train = scaler.transform(y_train)\n",
    "y_test = scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the features for the model\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Train the LSTM RNN\n",
    "\n",
    "In this section, you will design a custom LSTM RNN and fit (train) it using the training data.\n",
    "\n",
    "You will need to:\n",
    "1. Define the model architecture\n",
    "2. Compile the model\n",
    "3. Fit the model to the training data\n",
    "\n",
    "### Hints:\n",
    "You will want to use the same model architecture and random seed for both notebooks. This is necessary to accurately compare the performance of the FNG model vs the closing price model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model. \n",
    "# The return sequences need to be set to True if you are adding additional LSTM layers, but \n",
    "# You don't have to do this for the final layer. \n",
    "# Note: The dropouts help prevent overfitting\n",
    "# Note: The input shape is the number of time steps and the number of indicators\n",
    "# Note: Batching inputs has a different input shape of Samples/TimeSteps/Features\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "number_units = 30\n",
    "dropout_fraction = 0.2\n",
    "\n",
    "# Layer 1\n",
    "model.add(LSTM(\n",
    "    units = number_units,\n",
    "    return_sequences = True,\n",
    "    input_shape = (X_train.shape[1],1))\n",
    "         )\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Layer 2\n",
    "model.add(LSTM(\n",
    "    units = number_units,\n",
    "    return_sequences = True,\n",
    "        ))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Layer 3\n",
    "model.add(LSTM(\n",
    "    units = number_units,\n",
    "    return_sequences = False,\n",
    "        ))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 10, 30)            3840      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 30)            0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 10, 30)            7320      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 10, 30)            0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 30)                7320      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 18,511\n",
      "Trainable params: 18,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 [==============================] - 5s 14ms/step - loss: 0.0901\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0737\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0565\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0579\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0563\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.0490\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.0514\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0491\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 1s 13ms/step - loss: 0.0481\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0466\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.0455\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.0469\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0462\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0456\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0463\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0445\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0457\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0443\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.0453\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.0423\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.0425\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.0441\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.0423\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.0428\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.0431\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.0408\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0407\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.0409\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0405\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 1s 25ms/step - loss: 0.0400\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 0.0414\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.0390\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.0399\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.0403\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.0385\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.0404\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.0388\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 0.0381\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.0397\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0395\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.0378\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.0378\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.0380\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0380\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0375\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.0383\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.0392\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.0377\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.0388\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.0377\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.0380\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.0387\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.0369\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 0.0374\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.0375\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.0365\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.0377\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.0375\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.0359\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.0362\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.0373\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.0365\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 0.0364\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 0.0356\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.0361\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 0.0359\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 0.0360\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 0.0358\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 0.0358\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 0.0368\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 0.0352\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.0354\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 1s 25ms/step - loss: 0.0352\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 0.0360\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.0360\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.0355\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.0359\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 0.0356\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 0.0347\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.0352\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.0359\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.0370\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.0349\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.0358\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.0359\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.0351\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.0352\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.0336\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.0352\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.0349\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.0344\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.0353\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.0344\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.0349\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.0341\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.0339\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.0335\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.0343\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.0338\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.0341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fda58e5f8d0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "# Use at least 10 epochs\n",
    "# Do not shuffle the data\n",
    "# Experiement with the batch size, but a smaller batch size is recommended\n",
    "epochs = 100\n",
    "batch_size = 10\n",
    "model.fit(X_train, y_train, epochs=epochs, shuffle=False, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance\n",
    "\n",
    "In this section, you will evaluate the model using the test data. \n",
    "\n",
    "You will need to:\n",
    "1. Evaluate the model using the `X_test` and `y_test` data.\n",
    "2. Use the X_test data to make predictions\n",
    "3. Create a DataFrame of Real (y_test) vs predicted values. \n",
    "4. Plot the Real vs predicted values as a line chart\n",
    "\n",
    "### Hints\n",
    "Remember to apply the `inverse_transform` function to the predicted and y_test values to recover the actual closing prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 5ms/step - loss: 0.1020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10200484097003937"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some predictions\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the original prices instead of the scaled version\n",
    "predicted_prices = scaler.inverse_transform(predicted)\n",
    "real_prices = scaler.inverse_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-02-20</th>\n",
       "      <td>3924.239990</td>\n",
       "      <td>7177.097656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-21</th>\n",
       "      <td>3974.050049</td>\n",
       "      <td>7589.417969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-22</th>\n",
       "      <td>3937.040039</td>\n",
       "      <td>7807.895020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-23</th>\n",
       "      <td>3983.530029</td>\n",
       "      <td>8023.285645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-24</th>\n",
       "      <td>4149.089844</td>\n",
       "      <td>8206.264648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Real    Predicted\n",
       "2019-02-20  3924.239990  7177.097656\n",
       "2019-02-21  3974.050049  7589.417969\n",
       "2019-02-22  3937.040039  7807.895020\n",
       "2019-02-23  3983.530029  8023.285645\n",
       "2019-02-24  4149.089844  8206.264648"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame of Real and Predicted values\n",
    "stocks = pd.DataFrame({\n",
    "    \"Real\": real_prices.ravel(),\n",
    "    \"Predicted\": predicted_prices.ravel()\n",
    "}, index = df.index[-len(real_prices): ]) \n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='1449'>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"aed3ab4f-bf7c-4b30-9ca8-8df91ea7d392\" data-root-id=\"1449\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  function embed_document(root) {\n",
       "    var docs_json = {\"cc687d2c-22bc-49fd-a942-82f36144242b\":{\"defs\":[{\"extends\":null,\"module\":null,\"name\":\"ReactiveHTML1\",\"overrides\":[],\"properties\":[]},{\"extends\":null,\"module\":null,\"name\":\"FlexBox1\",\"overrides\":[],\"properties\":[{\"default\":\"flex-start\",\"kind\":null,\"name\":\"align_content\"},{\"default\":\"flex-start\",\"kind\":null,\"name\":\"align_items\"},{\"default\":\"row\",\"kind\":null,\"name\":\"flex_direction\"},{\"default\":\"wrap\",\"kind\":null,\"name\":\"flex_wrap\"},{\"default\":\"flex-start\",\"kind\":null,\"name\":\"justify_content\"}]},{\"extends\":null,\"module\":null,\"name\":\"TemplateActions1\",\"overrides\":[],\"properties\":[{\"default\":0,\"kind\":null,\"name\":\"open_modal\"},{\"default\":0,\"kind\":null,\"name\":\"close_modal\"}]},{\"extends\":null,\"module\":null,\"name\":\"MaterialTemplateActions1\",\"overrides\":[],\"properties\":[{\"default\":0,\"kind\":null,\"name\":\"open_modal\"},{\"default\":0,\"kind\":null,\"name\":\"close_modal\"}]}],\"roots\":{\"references\":[{\"attributes\":{},\"id\":\"1492\",\"type\":\"Selection\"},{\"attributes\":{\"children\":[{\"id\":\"1450\"},{\"id\":\"1455\"},{\"id\":\"1774\"}],\"margin\":[0,0,0,0],\"name\":\"Row02094\",\"tags\":[\"embedded\"]},\"id\":\"1449\",\"type\":\"Row\"},{\"attributes\":{\"days\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31]},\"id\":\"1511\",\"type\":\"DaysTicker\"},{\"attributes\":{\"days\":[1,4,7,10,13,16,19,22,25,28]},\"id\":\"1512\",\"type\":\"DaysTicker\"},{\"attributes\":{\"below\":[{\"id\":\"1464\"}],\"center\":[{\"id\":\"1467\"},{\"id\":\"1471\"}],\"height\":300,\"left\":[{\"id\":\"1468\"}],\"margin\":[5,5,5,5],\"min_border_bottom\":10,\"min_border_left\":10,\"min_border_right\":10,\"min_border_top\":10,\"renderers\":[{\"id\":\"1497\"},{\"id\":\"1530\"}],\"right\":[{\"id\":\"1521\"}],\"sizing_mode\":\"fixed\",\"title\":{\"id\":\"1456\"},\"toolbar\":{\"id\":\"1478\"},\"width\":700,\"x_range\":{\"id\":\"1451\"},\"x_scale\":{\"id\":\"1460\"},\"y_range\":{\"id\":\"1452\"},\"y_scale\":{\"id\":\"1462\"}},\"id\":\"1455\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1525\",\"type\":\"Selection\"},{\"attributes\":{\"days\":[1,8,15,22]},\"id\":\"1513\",\"type\":\"DaysTicker\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"syncable\":false,\"top_units\":\"screen\"},\"id\":\"1477\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"data_source\":{\"id\":\"1491\"},\"glyph\":{\"id\":\"1494\"},\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"1496\"},\"nonselection_glyph\":{\"id\":\"1495\"},\"selection_glyph\":{\"id\":\"1523\"},\"view\":{\"id\":\"1498\"}},\"id\":\"1497\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"label\":{\"value\":\"Predicted\"},\"renderers\":[{\"id\":\"1530\"}]},\"id\":\"1556\",\"type\":\"LegendItem\"},{\"attributes\":{\"line_color\":\"#30a2da\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"1523\",\"type\":\"Line\"},{\"attributes\":{\"days\":[1,15]},\"id\":\"1514\",\"type\":\"DaysTicker\"},{\"attributes\":{\"margin\":[5,5,5,5],\"name\":\"HSpacer02098\",\"sizing_mode\":\"stretch_width\"},\"id\":\"1450\",\"type\":\"Spacer\"},{\"attributes\":{},\"id\":\"1472\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"1541\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"data\":{\"Variable\":[\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\"],\"index\":{\"__ndarray__\":\"AABAO4OQdkIAAACh1ZB2QgAAwAYokXZCAACAbHqRdkIAAEDSzJF2QgAAADgfknZCAADAnXGSdkIAAIADxJJ2QgAAQGkWk3ZCAAAAz2iTdkIAAMA0u5N2QgAAgJoNlHZCAABAAGCUdkIAAABmspR2QgAAwMsElXZCAACAMVeVdkIAAECXqZV2QgAAAP37lXZCAADAYk6WdkIAAIDIoJZ2QgAAQC7zlnZCAAAAlEWXdkIAAMD5l5d2QgAAgF/ql3ZCAABAxTyYdkIAAAArj5h2QgAAwJDhmHZCAACA9jOZdkIAAEBchpl2QgAAAMLYmXZCAADAJyuadkIAAICNfZp2QgAAQPPPmnZCAAAAWSKbdkIAAMC+dJt2QgAAgCTHm3ZCAABAihmcdkIAAADwa5x2QgAAwFW+nHZCAACAuxCddkIAAEAhY512QgAAAIe1nXZCAADA7AeedkIAAIBSWp52QgAAQLisnnZCAAAAHv+edkIAAMCDUZ92QgAAgOmjn3ZCAABAT/afdkIAAAC1SKB2QgAAwBqboHZCAACAgO2gdkIAAEDmP6F2QgAAAEySoXZCAADAseShdkIAAIAXN6J2QgAAQH2JonZCAAAA49uidkIAAMBILqN2QgAAgK6Ao3ZCAABAFNOjdkIAAAB6JaR2QgAAwN93pHZCAACARcqkdkIAAECrHKV2QgAAABFvpXZCAADAdsGldkIAAIDcE6Z2QgAAQEJmpnZCAAAAqLimdkIAAMANC6d2QgAAgHNdp3ZCAABA2a+ndkIAAAA/Aqh2QgAAwKRUqHZCAACACqeodkIAAEBw+ah2QgAAANZLqXZCAADAO56pdkIAAICh8Kl2QgAAQAdDqnZCAAAAbZWqdkIAAMDS56p2QgAAgDg6q3ZCAABAnoyrdkIAAAAE36t2QgAAwGkxrHZCAACAz4OsdkIAAEA11qx2QgAAAJsorXZCAADAAHutdkIAAIBmza12QgAAQMwfrnZCAAAAMnKudkIAAMCXxK52QgAAgP0Wr3ZCAABAY2mvdkIAAADJu692QgAAwC4OsHZCAACAlGCwdkIAAED6srB2QgAAAGAFsXZCAADAxVexdkIAAIArqrF2QgAAQJH8sXZCAAAA906ydkIAAMBcobJ2QgAAgMLzsnZCAABAKEazdkIAAACOmLN2QgAAwPPqs3ZCAACAWT20dkIAAEC/j7R2QgAAACXitHZCAADAijS1dkIAAIDwhrV2QgAAQFbZtXZCAAAAvCu2dkIAAMAhfrZ2QgAAgIfQtnZCAABA7SK3dkIAAABTdbd2QgAAwLjHt3ZCAACAHhq4dkIAAECEbLh2QgAAAOq+uHZCAADATxG5dkIAAIC1Y7l2QgAAQBu2uXZCAAAAgQi6dkIAAMDmWrp2QgAAgEytunZCAABAsv+6dkIAAAAYUrt2QgAAwH2ku3ZCAACA4/a7dkIAAEBJSbx2QgAAAK+bvHZCAADAFO68dkIAAIB6QL12QgAAQOCSvXZCAAAARuW9dkIAAMCrN752QgAAgBGKvnZCAABAd9y+dkIAAADdLr92QgAAwEKBv3ZCAACAqNO/dkIAAEAOJsB2QgAAAHR4wHZCAADA2crAdkIAAIA/HcF2QgAAQKVvwXZCAAAAC8LBdkIAAMBwFMJ2QgAAgNZmwnZCAABAPLnCdkIAAACiC8N2QgAAwAdew3ZCAACAbbDDdkI=\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[160]},\"value\":{\"__ndarray__\":\"yEjgRVgr7UUp//NFSbr6RQ85AEYe5ANGx20KRlo4CEajqgVGDlYERof9/EUcHfNFcIzrRYz75UUjHt1FjsvURQNY0EWGctZFkHjdRSjh40WyU+lFmlbuRQ1r80WrtPZFsVn8RdU9AUYbAwNGD+wDRgtTBEYFgwRGSFkERoCGBkYjUgZGpHkERtr3AEaOM/1FuXP3RY528UUWPe9FvMvtRTGD8EUCGPFFYK72RVkW/EVjBgVG2q8HRv0bCkYCHw9GeacURuqkF0aBGBlGEvwZRicxG0ZOTRNGGasTRmk6EEZ9GRFG1wQMRgbGCkYpQwtGsKwKRlcTC0b8PwtGkcQORke2EUZXwBRGsWYTRs1TDkareglGkoADRqDm/UUymPRFWqrwRbIs7UX/tu9FSj32RYen/kVvPgFGtpMHRvPNC0bVaxJGul4ZRlVAIEa1ZiVG2jApRtCwK0ZCoy1GDVkwRnquLUYKmi9Ga+cwRlgjMkaPai9G7WYuRu6nKkascidGMLomRli/JEaJZSZGjzonRr8qJ0ZogydGk4AjRnSKIkZfmyJG+tIjRlKpGUaVmA5Gnt8FRp9c9UVuxfJFthbzRVLQ7UVRSvBFg/zyRZuT90U9qAFG2e0LRrggF0ZYtiNGhXYoRuObLEZnJjJGrb02Rnh/OUYAQjxGuV08RpukP0Y0ekJGb1xBRtXGN0Z6azxG4+k8RsVfOEY99zZG0Mo6RqjGOEbnFjNGEeovRhsEKkbyAS5G5xQyRteLMkZKfixGuCQiRg0SJkbM/CJG+Z0RRiTaCUY1nvlFUwroRYVI2UXHbM5F5YfMRdnjzkXYcsxFF3fERWmKxkV9d8NFqXDIRQ==\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[160]}},\"selected\":{\"id\":\"1525\"},\"selection_policy\":{\"id\":\"1541\"}},\"id\":\"1524\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"months\":[0,1,2,3,4,5,6,7,8,9,10,11]},\"id\":\"1515\",\"type\":\"MonthsTicker\"},{\"attributes\":{},\"id\":\"1473\",\"type\":\"PanTool\"},{\"attributes\":{\"months\":[0,2,4,6,8,10]},\"id\":\"1516\",\"type\":\"MonthsTicker\"},{\"attributes\":{},\"id\":\"1487\",\"type\":\"AllLabels\"},{\"attributes\":{},\"id\":\"1474\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"active_multi\":null,\"tools\":[{\"id\":\"1453\"},{\"id\":\"1472\"},{\"id\":\"1473\"},{\"id\":\"1474\"},{\"id\":\"1475\"},{\"id\":\"1476\"}]},\"id\":\"1478\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1469\",\"type\":\"BasicTicker\"},{\"attributes\":{\"line_color\":\"#fc4f30\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"1557\",\"type\":\"Line\"},{\"attributes\":{\"months\":[0,4,8]},\"id\":\"1517\",\"type\":\"MonthsTicker\"},{\"attributes\":{\"source\":{\"id\":\"1491\"}},\"id\":\"1498\",\"type\":\"CDSView\"},{\"attributes\":{\"overlay\":{\"id\":\"1477\"}},\"id\":\"1475\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"line_alpha\":0.2,\"line_color\":\"#30a2da\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"1496\",\"type\":\"Line\"},{\"attributes\":{\"months\":[0,6]},\"id\":\"1518\",\"type\":\"MonthsTicker\"},{\"attributes\":{\"line_color\":\"#30a2da\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"1494\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"1489\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1519\",\"type\":\"YearsTicker\"},{\"attributes\":{\"text_color\":\"black\",\"text_font_size\":\"12pt\"},\"id\":\"1456\",\"type\":\"Title\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#30a2da\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"1495\",\"type\":\"Line\"},{\"attributes\":{\"click_policy\":\"mute\",\"items\":[{\"id\":\"1522\"},{\"id\":\"1556\"}],\"location\":[0,0],\"title\":\"Variable\"},\"id\":\"1521\",\"type\":\"Legend\"},{\"attributes\":{\"axis_label\":\"Date\",\"formatter\":{\"id\":\"1486\"},\"major_label_policy\":{\"id\":\"1487\"},\"ticker\":{\"id\":\"1465\"}},\"id\":\"1464\",\"type\":\"DatetimeAxis\"},{\"attributes\":{\"label\":{\"value\":\"Real\"},\"renderers\":[{\"id\":\"1497\"}]},\"id\":\"1522\",\"type\":\"LegendItem\"},{\"attributes\":{},\"id\":\"1476\",\"type\":\"ResetTool\"},{\"attributes\":{\"margin\":[5,5,5,5],\"name\":\"HSpacer02099\",\"sizing_mode\":\"stretch_width\"},\"id\":\"1774\",\"type\":\"Spacer\"},{\"attributes\":{\"callback\":null,\"formatters\":{\"@{index}\":\"datetime\"},\"renderers\":[{\"id\":\"1497\"},{\"id\":\"1530\"}],\"tags\":[\"hv_created\"],\"tooltips\":[[\"Variable\",\"@{Variable}\"],[\"index\",\"@{index}{%F %T}\"],[\"value\",\"@{value}\"]]},\"id\":\"1453\",\"type\":\"HoverTool\"},{\"attributes\":{},\"id\":\"1506\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1486\",\"type\":\"DatetimeTickFormatter\"},{\"attributes\":{\"num_minor_ticks\":5,\"tickers\":[{\"id\":\"1508\"},{\"id\":\"1509\"},{\"id\":\"1510\"},{\"id\":\"1511\"},{\"id\":\"1512\"},{\"id\":\"1513\"},{\"id\":\"1514\"},{\"id\":\"1515\"},{\"id\":\"1516\"},{\"id\":\"1517\"},{\"id\":\"1518\"},{\"id\":\"1519\"}]},\"id\":\"1465\",\"type\":\"DatetimeTicker\"},{\"attributes\":{\"mantissas\":[1,2,5],\"max_interval\":500.0,\"num_minor_ticks\":0},\"id\":\"1508\",\"type\":\"AdaptiveTicker\"},{\"attributes\":{},\"id\":\"1462\",\"type\":\"LinearScale\"},{\"attributes\":{\"end\":13831.480297400001,\"reset_end\":13831.480297400001,\"reset_start\":2813.0800046,\"start\":2813.0800046,\"tags\":[[[\"value\",\"value\",null]]]},\"id\":\"1452\",\"type\":\"Range1d\"},{\"attributes\":{\"line_alpha\":0.2,\"line_color\":\"#fc4f30\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"1529\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"1460\",\"type\":\"LinearScale\"},{\"attributes\":{\"end\":1564358400000.0,\"reset_end\":1564358400000.0,\"reset_start\":1550620800000.0,\"start\":1550620800000.0,\"tags\":[[[\"index\",\"index\",null]]]},\"id\":\"1451\",\"type\":\"Range1d\"},{\"attributes\":{\"data_source\":{\"id\":\"1524\"},\"glyph\":{\"id\":\"1527\"},\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"1529\"},\"nonselection_glyph\":{\"id\":\"1528\"},\"selection_glyph\":{\"id\":\"1557\"},\"view\":{\"id\":\"1531\"}},\"id\":\"1530\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"axis\":{\"id\":\"1464\"},\"grid_line_color\":null,\"ticker\":null},\"id\":\"1467\",\"type\":\"Grid\"},{\"attributes\":{\"base\":24,\"mantissas\":[1,2,4,6,8,12],\"max_interval\":43200000.0,\"min_interval\":3600000.0,\"num_minor_ticks\":0},\"id\":\"1510\",\"type\":\"AdaptiveTicker\"},{\"attributes\":{\"source\":{\"id\":\"1524\"}},\"id\":\"1531\",\"type\":\"CDSView\"},{\"attributes\":{\"base\":60,\"mantissas\":[1,2,5,10,15,20,30],\"max_interval\":1800000.0,\"min_interval\":1000.0,\"num_minor_ticks\":0},\"id\":\"1509\",\"type\":\"AdaptiveTicker\"},{\"attributes\":{\"axis\":{\"id\":\"1468\"},\"dimension\":1,\"grid_line_color\":null,\"ticker\":null},\"id\":\"1471\",\"type\":\"Grid\"},{\"attributes\":{\"line_color\":\"#fc4f30\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"1527\",\"type\":\"Line\"},{\"attributes\":{\"axis_label\":\"Price\",\"formatter\":{\"id\":\"1489\"},\"major_label_policy\":{\"id\":\"1490\"},\"ticker\":{\"id\":\"1469\"}},\"id\":\"1468\",\"type\":\"LinearAxis\"},{\"attributes\":{\"data\":{\"Variable\":[\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\"],\"index\":{\"__ndarray__\":\"AABAO4OQdkIAAACh1ZB2QgAAwAYokXZCAACAbHqRdkIAAEDSzJF2QgAAADgfknZCAADAnXGSdkIAAIADxJJ2QgAAQGkWk3ZCAAAAz2iTdkIAAMA0u5N2QgAAgJoNlHZCAABAAGCUdkIAAABmspR2QgAAwMsElXZCAACAMVeVdkIAAECXqZV2QgAAAP37lXZCAADAYk6WdkIAAIDIoJZ2QgAAQC7zlnZCAAAAlEWXdkIAAMD5l5d2QgAAgF/ql3ZCAABAxTyYdkIAAAArj5h2QgAAwJDhmHZCAACA9jOZdkIAAEBchpl2QgAAAMLYmXZCAADAJyuadkIAAICNfZp2QgAAQPPPmnZCAAAAWSKbdkIAAMC+dJt2QgAAgCTHm3ZCAABAihmcdkIAAADwa5x2QgAAwFW+nHZCAACAuxCddkIAAEAhY512QgAAAIe1nXZCAADA7AeedkIAAIBSWp52QgAAQLisnnZCAAAAHv+edkIAAMCDUZ92QgAAgOmjn3ZCAABAT/afdkIAAAC1SKB2QgAAwBqboHZCAACAgO2gdkIAAEDmP6F2QgAAAEySoXZCAADAseShdkIAAIAXN6J2QgAAQH2JonZCAAAA49uidkIAAMBILqN2QgAAgK6Ao3ZCAABAFNOjdkIAAAB6JaR2QgAAwN93pHZCAACARcqkdkIAAECrHKV2QgAAABFvpXZCAADAdsGldkIAAIDcE6Z2QgAAQEJmpnZCAAAAqLimdkIAAMANC6d2QgAAgHNdp3ZCAABA2a+ndkIAAAA/Aqh2QgAAwKRUqHZCAACACqeodkIAAEBw+ah2QgAAANZLqXZCAADAO56pdkIAAICh8Kl2QgAAQAdDqnZCAAAAbZWqdkIAAMDS56p2QgAAgDg6q3ZCAABAnoyrdkIAAAAE36t2QgAAwGkxrHZCAACAz4OsdkIAAEA11qx2QgAAAJsorXZCAADAAHutdkIAAIBmza12QgAAQMwfrnZCAAAAMnKudkIAAMCXxK52QgAAgP0Wr3ZCAABAY2mvdkIAAADJu692QgAAwC4OsHZCAACAlGCwdkIAAED6srB2QgAAAGAFsXZCAADAxVexdkIAAIArqrF2QgAAQJH8sXZCAAAA906ydkIAAMBcobJ2QgAAgMLzsnZCAABAKEazdkIAAACOmLN2QgAAwPPqs3ZCAACAWT20dkIAAEC/j7R2QgAAACXitHZCAADAijS1dkIAAIDwhrV2QgAAQFbZtXZCAAAAvCu2dkIAAMAhfrZ2QgAAgIfQtnZCAABA7SK3dkIAAABTdbd2QgAAwLjHt3ZCAACAHhq4dkIAAECEbLh2QgAAAOq+uHZCAADATxG5dkIAAIC1Y7l2QgAAQBu2uXZCAAAAgQi6dkIAAMDmWrp2QgAAgEytunZCAABAsv+6dkIAAAAYUrt2QgAAwH2ku3ZCAACA4/a7dkIAAEBJSbx2QgAAAK+bvHZCAADAFO68dkIAAIB6QL12QgAAQOCSvXZCAAAARuW9dkIAAMCrN752QgAAgBGKvnZCAABAd9y+dkIAAADdLr92QgAAwEKBv3ZCAACAqNO/dkIAAEAOJsB2QgAAAHR4wHZCAADA2crAdkIAAIA/HcF2QgAAQKVvwXZCAAAAC8LBdkIAAMBwFMJ2QgAAgNZmwnZCAABAPLnCdkIAAACiC8N2QgAAwAdew3ZCAACAbbDDdkI=\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[160]},\"value\":{\"__ndarray__\":\"vCL433qorkBlxAWgGQyvQCHn/X8Uwq5A3Qn2Xw8fr0C+MQQAFzWwQGO1+X89d61ARN0HIAULrkCdSgaAwtOtQCP2CaBw7a1AY7X5f73erUB4RfC/9e6tQFde8j/hBa5AqaENwJ7IrUDdCfZfjyatQAIPDCBcRK5AeEXwv/VFrkAf2PFfOFWuQIi6D0AKOK5AvCL433rXrkCGqwMgrrOuQOEnDqDHRa5A//Dz3yNhrkBXXvI/4UyuQFde8j/hUq5AQs77/yiurkBE3QcgBXavQAAAAAAAPK9AyogLQLMpr0DhJw6gR3CvQAAAAACAsa9AAg8MINw5r0CGqwMgrkGvQN8YAoBrTq9AH9jxXzg0r0BlxAWgGamuQCP2CaBwzK5AeUXwv/Wbr0CbO/pf5oivQE4lA0BhD7BATiUDQCEWsEArL/mfsBCwQHpU/N9RN7BAhqsDIO4qs0C/MQQAl3CzQApI+x9cMbNAvCL43zq3s0AAAAAAQMGzQELO+/8oUbRAvjEEABeutEAtPgXATFG0QGXEBaCZxrRA1dAGYI+4s0D/////f9mzQELO+/+o2LNAvjEEAJcttEBD3QcgRa2zQNXQBmDPXLRAnUoGgEJ0tED/////v6m0QOlg/Z+Hr7RAhqsDIC7OtEBjtfl/vbm0QN8YAoCrErVAZcQFoBmjtUAh5/1/lE61QOAYAoCrKrRAvjEEABdytEC7Ivjfem20QNPB+j9zmLRAbwwBwPV1tED2twTgo+a0QJHz/j+KDbVAF58CYLh8tUBOJQNAYXm2QCHn/X8U0LZA9rcE4COitkDfGAKAK3S2QHpU/N+Ru7ZAbwwBwLVut0BvDAHA9Ru4QJHz/j9K1rhACkj7H1wXvEBOJQNAoUG7QApI+x9cfr5ATiUDQCEsv0Ag5/1/1Pe/QApI+x8cwr5AbwwBwPXLvEAh5/1/FGK8QHpU/N+RAMBAkfP+P0o+v0CGqwMg7gu/QPa3BODjyr1AAAAAAIDEvkCbO/pfZjy/QE4lA0Ahe79A3xgCgB0LwUBvDAHAlSjBQLLa/L9sB8FA6WD9n0fswED/////HyrAQG8MAcBVs8BAWW3+X++1wEAg5/1/9BDBQGK1+X99sr9AF58CYHj9vUCR8/4/Sm++QApI+x9cf75ATyUDQKFCv0DpYP2fx/2+QCwv+Z9w271AAAAAAABVv0B6VPzfUe2+QPW3BOAj7r9AvjEEAMkVwEA4hgDg+vrAQOlg/Z/HSsFAvjEEAJeJwUBOJQNAATzCQDiGAODavMFAyHn/H0UgwkCy2vy/bKDCQFlt/l9v9cNAyHn/H8XgxECy2vy//jPFQLLa/L/ejcVA3xgCgCvuxkB6VPzfozjJQOAYAoALycVA6WD9n4chyECz2vy/DDbHQBefAmCGCMVAWG3+X++vxECnkgGgEC7FQIarAyDOZsdAIef9f0LKxUAAAAAAoHjFQBefAmB4+MVAeVT83yNpxkAi5/1/FATIQCHn/X+Ci8hAWW3+X4+hx0BZbf5fjyfGQFlt/l+vCsdAhqsDIPwxxkAh5/1/NO7DQE4lA0AhMcVAFp8CYLhnwkBOJQNAE/DCQLLa/L8sx8RAF58CYHiSxEBwDAHAtQPFQDiGAOBarcRAWW3+X+8qxEBOJQNAEz/DQHtU/N8RFsNAvjEEADdNw0DpYP2fuTvDQL4xBAApg8JAIOf9f+KdwkA=\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[160]}},\"selected\":{\"id\":\"1492\"},\"selection_policy\":{\"id\":\"1506\"}},\"id\":\"1491\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#fc4f30\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"1528\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"1490\",\"type\":\"AllLabels\"}],\"root_ids\":[\"1449\"]},\"title\":\"Bokeh Application\",\"version\":\"2.3.2\"}};\n",
       "    var render_items = [{\"docid\":\"cc687d2c-22bc-49fd-a942-82f36144242b\",\"root_ids\":[\"1449\"],\"roots\":{\"1449\":\"aed3ab4f-bf7c-4b30-9ca8-8df91ea7d392\"}}];\n",
       "    root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "  }\n",
       "  if (root.Bokeh !== undefined && root.Bokeh.Panel !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined && root.Bokeh.Panel !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ],
      "text/plain": [
       ":NdOverlay   [Variable]\n",
       "   :Curve   [index]   (value)"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "1449"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the real vs predicted values as a line chart\n",
    "stocks.hvplot.line(xlabel=\"Date\", ylabel=\"Price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python [conda env:pyvizenv2] *",
   "language": "python",
   "name": "conda-env-pyvizenv2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
